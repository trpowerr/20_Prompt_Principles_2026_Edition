### 20 принципов эффективного промптинга: Исследования 2025 года

#### КАТЕГОРИЯ 1: САМЫЕ НЕОБХОДИМЫЕ ПРИНЦИПЫ
Эти методы имеют наивысшую доказанную эффективность и универсальны для ChatGPT, Gemini и Claude.

1. **Максимальная ясность и специфичность**
Инструкции должны быть предельно конкретными, без двусмысленных формулировок. Исследования показывают, что чем точнее определена задача, тем меньше модель склонна к галлюцинациям. Всегда указывайте желаемую длину, формат и стиль ответа в самом начале.
*Источник: Официальная документация OpenAI и Google.*

2. **Использование разделителей (###, """, < >)**
Разделители помогают модели четко отличить саму инструкцию от текста, который нужно обработать. Это предотвращает «смешивание» команд и данных, особенно в длинных запросах. Применение тройных кавычек или хештегов является стандартом для структурирования запроса.
*Источник: Документация OpenAI.*

3. **Few-Shot промптинг (Обучение на примерах)**
Предоставление 2–3 образцов «входные данные — идеальный ответ» значительно повышает точность следования формату. Это особенно эффективно для задач классификации и извлечения данных. Однако для некоторых моделей, таких как DeepSeek R1, избыток примеров может снизить качество рассуждений.
*Источник: Исследования AgentIF и документация Google Gemini.*

4. **Использование XML-тегов для структуры**
Для Claude и Gemini использование тегов типа `<context>`, `<task>` или `<output_format>` является наиболее эффективным способом управления вниманием модели. Это позволяет модели игнорировать нерелевантные части текста и фокусироваться на главных требованиях.
*Источник: Официальные рекомендации Anthropic и Google.*

5. **Назначение экспертной роли (Persona)**
Установка контекста через роль («Ты — старший программист», «Ты — профессиональный редактор») заставляет модель использовать специфическую терминологию и соответствующий тон. Исследования подтверждают, что ролевые инструкции улучшают качество ответов в 57% случаев.
*Источник: Исследование «Principled Instructions Are All You Need».*

6. **Утвердительные команды (Do вместо Don't)**
Модели лучше понимают прямые указания «сделай это», чем запреты «не делай того». Если нужно что-то запретить, лучше сформулируйте это как положительное требование к формату (например, «пиши только на английском» вместо «не используй другие языки»).
*Источник: Исследование «Principled Instructions Are All You Need».*

7. **Перефразирование задачи (Rephrase and Respond)**
Перед выполнением сложной задачи попросите модель сначала пересказать инструкцию своими словами. Этот метод («Rephrase») доказанно улучшает точность рекомендаций и логических выводов в бюджетных моделях.
*Источник: Исследование RecSys 2025 (Kusano et al.).*

8. **Добавление справочного контекста (Background Knowledge)**
Явное включение в промпт теоретических знаний или фактов, необходимых для решения задачи, снижает риск ошибок. Это «якорит» рассуждения модели на предоставленных данных, а не на общих знаниях из базы обучения.
*Источник: Исследование RecSys 2025 (Kusano et al.).*

9. **Декомпозиция (Разбиение задачи на шаги)**
Сложные инструкции с множеством условий (multi-constraint) часто приводят к пропуску части требований. Разделение большого запроса на последовательность мелких подзадач в рамках одного чата повышает вероятность успеха на 20–30%.
*Источник: Исследование AgentIF и EIFBENCH.*

10. **Выходные праймеры (Output Primers)**
Завершайте промпт первыми символами или словами желаемого ответа (например, «Вот готовый JSON-объект: {»). Это гарантирует, что модель начнет ответ сразу в нужном формате, минуя лишние вежливые вступления.
*Источник: Исследование «Principled Instructions Are All You Need».*

---

#### КАТЕГОРИЯ 2: ПОЛЕЗНЫЕ ПРИНЦИПЫ
Эти методы эффективны в специфических сценариях (логика, длинные тексты) или при использовании продвинутых моделей.

11. **Цепочка рассуждений (Chain-of-Thought)**
Фраза «думай пошагово» критически важна для математических и логических задач. Однако для творческих задач или персональных рекомендаций она может снижать точность из-за «избыточного мышления» (overthinking).
*Источник: RecSys 2025 и Google/OpenAI рекомендации.*

12. **Эффект первичности (Instruction Primacy)**
В длинных промптах модели склонны лучше следовать инструкциям, расположенным в самом начале или в самом конце. Помещайте самые критические ограничения (например, лимит слов или запретные темы) в начало промпта.
*Источник: Исследование IFScale 2025.*

13. **Использование режима «мышления» (Thinking Mode)**
Для Claude 3.7 и моделей серии o1 активация режима глубокого рассуждения (thinking) значительно повышает качество выполнения сложных многосоставных инструкций. Это компенсирует нехватку данных в самом промпте за счет дополнительных вычислительных ресурсов на стороне модели.
*Источник: Исследование IFScale 2025.*

14. **Интерактивное уточнение (Ask for details)**
Просите модель задавать вам вопросы, если информации недостаточно для выполнения задачи (фраза: «С этого момента спрашивай меня, пока не соберешь все данные»). Это предотвращает додумывание (галлюцинации) со стороны ИИ при нечетких вводных.
*Источник: Исследование «Principled Instructions Are All You Need».*

15. **Мета-контракты (Приоритизация инструкций)**
Явно указывайте, какая из инструкций важнее в случае возникновения конфликта (например, «Если формат данных противоречит краткости, выбери точность формата»). Это решает проблему «мета-ограничений», с которыми часто не справляются современные агенты.
*Источник: Исследование AgentIF.*

16. **Использование встраиваний (Context Injection)**
При работе с документами ссылайтесь на конкретные разделы или ключевые слова из них, чтобы модель «зацепилась» за нужный пласт информации. Это особенно эффективно при обработке инструкций объемом более 1700 слов.
*Источник: Исследование AgentIF.*

---

#### КАТЕГОРИЯ 3: ПРИНЦИПЫ С СОМНИТЕЛЬНОЙ ЭФФЕКТИВНОСТЬЮ
Эффективность этих методов либо опровергнута в 2025 году, либо они не работают на современных мощных моделях (ceiling effect).

17. **Чрезмерная вежливость**
Добавление фраз «пожалуйста», «будь добр», «заранее спасибо» не только не улучшает ответ, но и может снижать его четкость. Современные модели работают эффективнее с прямыми и лаконичными директивами.
*Источник: Исследование «Principled Instructions Are All You Need».*

18. **Предложение «чаевых» (Tipping)**
Популярный ранее лайфхак с фразой «Я заплачу $200 за лучший ответ» у современных моделей (GPT-4o, Claude 3.5) практически не дает прироста. Исследования USMLE на разных версиях ChatGPT показали, что этот эффект «обнулился» с выходом новых архитектур.
*Источник: Исследование «Impact of Prompt Engineering on ChatGPT».*

19. **Эмоциональное давление**
Фразы типа «Это вопрос жизни и смерти» или «Это важно для моей карьеры» показывают всё меньшую эффективность. Для топовых моделей (GPT-4o, Claude 3.5) влияние таких стимулов статистически незначимо.
*Источник: Исследование RecSys 2025 и отчет NIH 2025.*

20. **Принудительное пошаговое рассуждение (Overthinking)**
Автоматическое добавление «думай шаг за шагом» к любой задаче может ухудшить результат в творческих запросах или персонализированных рекомендациях. Исследования 2025 года зафиксировали падение точности из-за того, что модель начинает «зацикливаться» на логике там, где требуется интуиция или стиль.
*Источник: Исследование RecSys 2025 (Kusano et al.).*

***
